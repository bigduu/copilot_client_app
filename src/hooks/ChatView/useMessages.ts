import { useState, useCallback } from "react";
import { invoke, Channel } from "@tauri-apps/api/core";
import useMessageProcessor from "./useMessageProcessor";
import { ChatItem, Message } from "../../types/chat";
import { DEFAULT_MESSAGE } from "../../constants";
import { ToolExecutionResult } from "./useToolExecution";
import { messageProcessor as messageProcessorService } from "../../services/MessageProcessor";

// System prompt storage key
const SYSTEM_PROMPT_KEY = "system_prompt";

interface UseMessagesReturn {
  isStreaming: boolean;
  setIsStreaming: (streaming: boolean) => void;
  activeChannel: Channel<string> | null;
  sendMessage: (content: string) => Promise<void>;
  addAssistantMessage: (message: Message) => void;
  initiateAIResponse: () => Promise<void>;
  // æ–°å¢MessageProcessorç›¸å…³çŠ¶æ€å’Œæ–¹æ³•
  messageProcessor: ReturnType<typeof useMessageProcessor>;
}

const getEffectiveSystemPrompt = (chat: ChatItem | null) => {
  if (!chat) return localStorage.getItem(SYSTEM_PROMPT_KEY) || DEFAULT_MESSAGE;
  
  // First try to use chat's stored systemPrompt
  if (chat.systemPrompt) {
    return chat.systemPrompt;
  }
  
  // Look for existing system message
  const systemMessage = chat.messages.find(m => m.role === "system");
  if (systemMessage) {
    return systemMessage.content;
  }
  
  // Fall back to current global system prompt
  return localStorage.getItem(SYSTEM_PROMPT_KEY) || DEFAULT_MESSAGE;
};

export const useMessages = (
  currentChatId: string | null,
  updateChatMessages: (chatId: string, messages: Message[]) => void,
  currentMessages: Message[],
  currentChat: ChatItem | null = null
): UseMessagesReturn => {
  const [isStreaming, setIsStreaming] = useState(false);
  const [activeChannel, setActiveChannel] = useState<Channel<string> | null>(null);
  
  // é›†æˆMessageProcessoråŠŸèƒ½
  const messageProcessor = useMessageProcessor();

  // Add assistant message when streaming is complete
  const addAssistantMessage = useCallback(
    (message: Message) => { // Renamed assistantMessage to message for consistency with instructions
      if (currentChatId) {
        // Ensure the message has an ID
        const finalMessage = { // Renamed messageWithId to finalMessage for consistency
          ...message,
          id: message.id || crypto.randomUUID(),
        };
        
        const updatedMessages = [...currentMessages, finalMessage];
        updateChatMessages(currentChatId, updatedMessages);
        
        // Reset streaming state and clear active channel
        setIsStreaming(false);
        setActiveChannel(null);
      } else {
        console.error("Cannot add assistant message: No current chat");
        setIsStreaming(false);
      }
    },
    [currentChatId, currentMessages, updateChatMessages]
  );

  const sendMessage = useCallback(
    async (content: string) => {
      if (isStreaming) {
        console.error("Cannot send message while streaming");
        return;
      }

      if (!content.trim()) {
        console.error("Cannot send empty message");
        return;
      }

      if (!currentChatId) {
        console.error("No current chat ID - cannot send message");
        return;
      }

      try {
        console.log("[useMessages] Processing message through MessageProcessor");

        // ğŸš€ ä½¿ç”¨MessageProcessorå¤„ç†æ¶ˆæ¯æµç¨‹
        const { preprocessedMessages, onResponseComplete } = await messageProcessor.processMessageFlow(
          content,
          currentMessages
        );

        console.log("[useMessages] Message preprocessed, enhanced messages count:", preprocessedMessages.length);

        // æ›´æ–°èŠå¤©çŠ¶æ€ï¼Œæ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        const userMessage = preprocessedMessages[preprocessedMessages.length - 1]; // ç”¨æˆ·æ¶ˆæ¯æ˜¯æœ€åä¸€ä¸ª
        updateChatMessages(currentChatId, [...currentMessages, userMessage]);

        // å»¶è¿Ÿç¡®ä¿çŠ¶æ€æ›´æ–°
        await new Promise((resolve) => setTimeout(resolve, 100));

        // åˆ›å»ºchannelè¿›è¡Œæµå¼é€šä¿¡
        const channel = new Channel<string>();
        setActiveChannel(channel);
        setIsStreaming(true);

        await new Promise((resolve) => setTimeout(resolve, 100));

        console.log("[useMessages] Sending preprocessed messages to backend");

        // å‘é€ç»è¿‡MessageProcessorå¢å¼ºçš„æ¶ˆæ¯åˆ°åç«¯
        await invoke("execute_prompt", {
          messages: preprocessedMessages, // ğŸ¯ ä½¿ç”¨å¢å¼ºåçš„æ¶ˆæ¯
          channel: channel,
          model: currentChat?.model,
        }).catch((error) => {
          console.error("Error invoking execute_prompt:", error);
          addAssistantMessage({
            role: "assistant",
            content: `Error: ${error instanceof Error ? error.message : String(error)}`,
            id: crypto.randomUUID(),
          });
        });

        // ğŸ”„ åœ¨streamingç»“æŸåä¼šé€šè¿‡StreamingMessageItemè°ƒç”¨onResponseCompleteå¤„ç†å·¥å…·
        // æˆ‘ä»¬éœ€è¦å°†onResponseCompleteå­˜å‚¨èµ·æ¥ä¾›åç»­ä½¿ç”¨
        (window as any).__currentResponseProcessor = onResponseComplete;

      } catch (error) {
        console.error("Failed to process message with MessageProcessor:", error);
        setIsStreaming(false);
      }
    },
    [
      currentChatId,
      isStreaming,
      currentMessages,
      currentChat,
      addAssistantMessage,
      updateChatMessages,
      messageProcessor
    ]
  );

  const initiateAIResponse = useCallback(async () => {
    if (isStreaming) {
      console.error("Cannot initiate AI response while already streaming");
      return;
    }
    if (!currentChatId || !currentChat || currentMessages.length === 0) {
      console.error("Cannot initiate AI response: No current chat, or chat is empty.");
      return;
    }

    // Ensure the last message is from the user, otherwise, AI might respond to itself or system.
    const lastMessage = currentMessages[currentMessages.length - 1];
    if (lastMessage.role === 'system') {
        console.warn("Last message is system, AI response not initiated.");
        return;
    }

    let messagesToProcess = [...currentMessages];
    if (lastMessage.role === 'assistant') {
      // Remove the last assistant message
      messagesToProcess = currentMessages.slice(0, -1);
      updateChatMessages(currentChatId, messagesToProcess);
    }

    try {
      console.log("[useMessages] Initiating AI response through MessageProcessor");

      // ğŸš€ ä½¿ç”¨MessageProcessoræœåŠ¡é¢„å¤„ç†æ¶ˆæ¯ï¼ˆä¸æ·»åŠ æ–°çš„ç”¨æˆ·æ¶ˆæ¯ï¼‰
      const preprocessedMessages = await messageProcessorService.preprocessMessages(messagesToProcess);
      
      console.log("[useMessages] Messages preprocessed for AI response, enhanced count:", preprocessedMessages.length);

      // åˆ›å»ºchannelè¿›è¡Œæµå¼é€šä¿¡
      const channel = new Channel<string>();
      setActiveChannel(channel);
      setIsStreaming(true);

      await new Promise((resolve) => setTimeout(resolve, 100));

      console.log("[useMessages] Sending preprocessed messages for AI response");

      // å‘é€ç»è¿‡MessageProcessorå¢å¼ºçš„æ¶ˆæ¯åˆ°åç«¯
      await invoke("execute_prompt", {
        messages: preprocessedMessages, // ğŸ¯ ä½¿ç”¨å¢å¼ºåçš„æ¶ˆæ¯
        channel: channel,
        model: currentChat?.model,
      }).catch((error) => {
        console.error("Error invoking execute_prompt for AI response:", error);
        addAssistantMessage({
          role: "assistant",
          content: `Error: ${error instanceof Error ? error.message : String(error)}`,
          id: crypto.randomUUID(),
        });
      });

      // ğŸ”„ åˆ›å»ºå“åº”å¤„ç†å™¨ç”¨äºå¤„ç†AIå›å¤ä¸­çš„å·¥å…·è°ƒç”¨
      const onResponseComplete = async (aiResponse: string): Promise<ToolExecutionResult[]> => {
        console.log("[useMessages] Processing AI response for tool calls");
        const toolCalls = messageProcessorService.parseToolCalls(aiResponse);
        
        if (toolCalls.length === 0) return [];

        const { autoExecuted, pendingApproval } = await messageProcessorService.executeTools(toolCalls);
        
        if (pendingApproval.length > 0) {
          console.log(`[useMessages] ${pendingApproval.length} tools require user approval`);
          // é€šè¿‡äº‹ä»¶å‘é€å¾…å®¡æ‰¹å·¥å…·ï¼Œä¼šè¢«useMessageProcessorç›‘å¬åˆ°
          const event = new CustomEvent('tools-pending-approval', {
            detail: { toolCalls: pendingApproval }
          });
          window.dispatchEvent(event);
        }

        return autoExecuted;
      };

      // å­˜å‚¨å“åº”å¤„ç†å™¨ä¾›StreamingMessageItemä½¿ç”¨
      (window as any).__currentResponseProcessor = onResponseComplete;

    } catch (error) {
      console.error("Failed to initiate AI response with MessageProcessor:", error);
      setIsStreaming(false);
    }
  }, [
    currentChatId,
    isStreaming,
    currentMessages,
    currentChat,
    addAssistantMessage,
    updateChatMessages,
    messageProcessor
  ]);

  return {
    isStreaming,
    setIsStreaming,
    activeChannel,
    sendMessage,
    addAssistantMessage,
    initiateAIResponse,
    messageProcessor,
  };
};
