# Signal-Pull æ¶æ„å®æ–½è®¡åˆ’

**æ—¥æœŸ**: 2025-11-08  
**çŠ¶æ€**: è®¾è®¡é”å®šï¼Œå¼€å§‹å®æ–½  
**æ¶æ„**: ä¸Šä¸‹æ–‡æœ¬åœ°æ¶ˆæ¯æ±  + ä¿¡ä»¤-æ‹‰å–åŒæ­¥æ¨¡å‹

---

## âœ… å·²å®Œæˆä»»åŠ¡

### 1. Design æ–‡æ¡£æ›´æ–° âœ…

å·²æ·»åŠ ä¸¤ä¸ªå…³é”®å†³ç­–åˆ° `design.md`:

#### Decision 3.1: Context-Local Message Pool
- **å­˜å‚¨ç»“æ„**: `contexts/{ctx_id}/messages_pool/`
- **å…³é”®ç‰¹æ€§**: 
  - æ¯ä¸ª Context å®Œå…¨è‡ªåŒ…å«
  - åˆ†æ”¯æ“ä½œé›¶æ–‡ä»¶ I/O
  - æ— éœ€åƒåœ¾å›æ”¶
- **æ–‡ä»¶ä½ç½®**: design.md:1086-1181

#### Decision 4.5.1: Signal-Pull Synchronization Model
- **SSE ä¿¡ä»¤**: åªæ¨é€è½»é‡çº§é€šçŸ¥ï¼ˆ< 1KBï¼‰
- **REST æ‹‰å–**: å‰ç«¯ä¸»åŠ¨è·å–æ•°æ®
- **è‡ªæ„ˆæœºåˆ¶**: é€šè¿‡åºåˆ—å·è‡ªåŠ¨ä¿®å¤ä¸¢å¤±çš„ä¿¡ä»¤
- **æ–‡ä»¶ä½ç½®**: design.md:1296-1506

### 2. OpenSpec éªŒè¯ âœ…

```bash
$ openspec validate refactor-context-session-architecture --strict
âœ… Change 'refactor-context-session-architecture' is valid
```

---

## ğŸš§ å¾…å®æ–½ä»»åŠ¡

æ ¹æ®ç”¨æˆ·ç¡®è®¤çš„è®¾è®¡ï¼Œä»¥ä¸‹æ˜¯è¯¦ç»†çš„å®æ–½è®¡åˆ’ï¼š

### Phase 1.5: StreamingResponse & Signal-Pull Infrastructure

#### Task 1.5.1: æ‰©å±• MessageMetadata â³

**ç›®æ ‡**: æ·»åŠ æ¶ˆæ¯æ¥æºå’Œæµå¼å…ƒæ•°æ®å­—æ®µ

**æ–‡ä»¶**: `crates/context_manager/src/structs/metadata.rs`

**æ–°å¢ç»“æ„**:

```rust
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct MessageMetadata {
    // ç°æœ‰å­—æ®µ
    pub created_at: Option<DateTime<Utc>>,
    pub duration_ms: Option<u64>,
    pub tokens: Option<TokenUsage>,
    
    // âœ¨ æ–°å¢å­—æ®µ
    /// æ¶ˆæ¯æ¥æºï¼ˆç”¨æˆ·è¾“å…¥ vs AIç”Ÿæˆ vs å·¥å…·ç»“æœï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub source: Option<MessageSource>,
    
    /// å‰ç«¯å±•ç¤ºæç¤º
    #[serde(skip_serializing_if = "Option::is_none")]
    pub display_hint: Option<DisplayHint>,
    
    /// æµå¼å“åº”å…ƒæ•°æ®ï¼ˆå¦‚æœæ˜¯ StreamingResponseï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub streaming: Option<StreamingMetadata>,
    
    /// å‰ç«¯åŸå§‹è¾“å…¥ï¼ˆç”¨äºå›æ˜¾ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub original_input: Option<String>,
    
    /// è¿½è¸ª IDï¼ˆå‰åç«¯å…³è”ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub trace_id: Option<String>,
    
    // ä¿ç•™æ‰©å±•å­—æ®µ
    pub extra: Option<HashMap<String, Value>>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum MessageSource {
    UserInput,
    UserFileReference,
    UserWorkflow,
    UserImageUpload,
    AIGenerated,
    ToolExecution,
    SystemControl,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct DisplayHint {
    /// å‰ç«¯å±•ç¤ºçš„ç¼©ç•¥æ–‡æœ¬
    pub summary: Option<String>,
    /// æ˜¯å¦æŠ˜å æ˜¾ç¤º
    pub collapsed: bool,
    /// å›¾æ ‡æç¤º
    pub icon: Option<String>,
}

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct StreamingMetadata {
    pub chunks_count: usize,
    pub started_at: DateTime<Utc>,
    pub completed_at: DateTime<Utc>,
    pub total_duration_ms: u64,
    pub average_chunk_interval_ms: Option<f64>,
}
```

**æµ‹è¯•**:
- `test_message_source_serialization`
- `test_display_hint_defaults`
- `test_streaming_metadata_calculation`

---

#### Task 1.5.2: å®ç° StreamingResponse æ¶ˆæ¯ç±»å‹ â³

**ç›®æ ‡**: æ·»åŠ ä¸“é—¨çš„æµå¼å“åº”æ¶ˆæ¯ç±»å‹

**æ–‡ä»¶**: `crates/context_manager/src/structs/message_types.rs`

**æ–°å¢å†…å®¹**:

```rust
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum RichMessageType {
    // ... ç°æœ‰ç±»å‹
    
    /// æµå¼å“åº”æ¶ˆæ¯ï¼ˆLLM æµå¼ç”Ÿæˆçš„å®Œæ•´è®°å½•ï¼‰
    StreamingResponse(StreamingResponseMsg),
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct StreamingResponseMsg {
    /// å®Œæ•´çš„æœ€ç»ˆå†…å®¹
    pub content: String,
    
    /// æµå¼å—åºåˆ—ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰
    pub chunks: Vec<StreamChunk>,
    
    /// æµå¼å¼€å§‹æ—¶é—´
    pub started_at: DateTime<Utc>,
    
    /// æµå¼å®Œæˆæ—¶é—´
    pub completed_at: DateTime<Utc>,
    
    /// æ€»è€—æ—¶ï¼ˆæ¯«ç§’ï¼‰
    pub total_duration_ms: u64,
    
    /// LLM æ¨¡å‹åç§°
    #[serde(skip_serializing_if = "Option::is_none")]
    pub model: Option<String>,
    
    /// Token ä½¿ç”¨æƒ…å†µ
    #[serde(skip_serializing_if = "Option::is_none")]
    pub usage: Option<TokenUsage>,
    
    /// å®ŒæˆåŸå› ï¼ˆstop, length, tool_calls ç­‰ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub finish_reason: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct StreamChunk {
    /// å—åºåˆ—å·ï¼ˆä» 0 å¼€å§‹ï¼‰
    pub sequence: u64,
    
    /// å¢é‡å†…å®¹ï¼ˆdeltaï¼‰
    pub delta: String,
    
    /// å—æ¥æ”¶æ—¶é—´
    pub timestamp: DateTime<Utc>,
    
    /// åˆ°æ­¤å—ä¸ºæ­¢çš„ç´¯ç§¯å­—ç¬¦æ•°
    pub accumulated_chars: usize,
    
    /// ä¸ä¸Šä¸€å—çš„æ—¶é—´é—´éš”ï¼ˆæ¯«ç§’ï¼‰
    #[serde(skip_serializing_if = "Option::is_none")]
    pub interval_ms: Option<u64>,
}

impl StreamingResponseMsg {
    pub fn new(model: Option<String>) -> Self {
        let now = Utc::now();
        Self {
            content: String::new(),
            chunks: Vec::new(),
            started_at: now,
            completed_at: now,
            total_duration_ms: 0,
            model,
            usage: None,
            finish_reason: None,
        }
    }
    
    pub fn append_chunk(&mut self, delta: String) {
        let sequence = self.chunks.len() as u64;
        let timestamp = Utc::now();
        
        let interval_ms = if let Some(last_chunk) = self.chunks.last() {
            Some((timestamp - last_chunk.timestamp).num_milliseconds() as u64)
        } else {
            None
        };
        
        self.content.push_str(&delta);
        
        self.chunks.push(StreamChunk {
            sequence,
            delta,
            timestamp,
            accumulated_chars: self.content.len(),
            interval_ms,
        });
    }
    
    pub fn finalize(&mut self, finish_reason: Option<String>, usage: Option<TokenUsage>) {
        self.completed_at = Utc::now();
        self.total_duration_ms = (self.completed_at - self.started_at)
            .num_milliseconds() as u64;
        self.finish_reason = finish_reason;
        self.usage = usage;
    }
}
```

**æµ‹è¯•**:
- `test_streaming_response_creation`
- `test_append_chunk_sequence`
- `test_finalize_calculates_duration`
- `test_chunk_interval_calculation`

---

#### Task 1.5.3: Context é›†æˆæµå¼å¤„ç† â³

**ç›®æ ‡**: åœ¨ ChatContext ä¸­æ·»åŠ æµå¼å¤„ç†æ–¹æ³•

**æ–‡ä»¶**: `crates/context_manager/src/structs/context_lifecycle.rs`

**æ–°å¢æ–¹æ³•**:

```rust
impl ChatContext {
    /// å¼€å§‹æµå¼å“åº”ï¼ˆåˆ›å»ºæ¶ˆæ¯å¼•ç”¨ï¼‰
    pub fn begin_streaming_llm_response(&mut self, model: Option<String>) -> Result<Uuid> {
        // åˆ›å»ºæ¶ˆæ¯ ID
        let message_id = Uuid::new_v4();
        
        // åˆ›å»º StreamingResponse
        let streaming_msg = StreamingResponseMsg::new(model);
        let internal_msg = InternalMessage::from_rich(
            Role::Assistant,
            RichMessageType::StreamingResponse(streaming_msg)
        );
        
        // æ·»åŠ åˆ° message_pool
        let msg_node = MessageNode {
            id: message_id,
            message: internal_msg,
            parent_id: self.get_active_branch().message_ids.last().copied(),
        };
        
        self.message_pool.insert(message_id, msg_node);
        self.get_active_branch_mut().message_ids.push(message_id);
        
        // çŠ¶æ€è½¬æ¢
        self.current_state = ContextState::StreamingLLMResponse { 
            chunks_received: 0,
            chars_accumulated: 0 
        };
        
        self.mark_dirty();
        Ok(message_id)
    }
    
    /// è¿½åŠ æµå¼å—
    pub fn append_streaming_chunk(&mut self, message_id: Uuid, delta: String) -> Result<u64> {
        let msg_node = self.message_pool.get_mut(&message_id)
            .ok_or_else(|| anyhow!("Message not found: {}", message_id))?;
        
        // æ›´æ–° StreamingResponse
        if let Some(RichMessageType::StreamingResponse(streaming)) = &mut msg_node.message.rich_type {
            streaming.append_chunk(delta);
            
            // æ›´æ–°çŠ¶æ€
            self.current_state = ContextState::StreamingLLMResponse {
                chunks_received: streaming.chunks.len(),
                chars_accumulated: streaming.content.len(),
            };
            
            self.mark_dirty();
            
            // è¿”å›å½“å‰åºåˆ—å·
            Ok(streaming.chunks.len() as u64)
        } else {
            Err(anyhow!("Message is not a StreamingResponse"))
        }
    }
    
    /// å®Œæˆæµå¼å“åº”
    pub fn finalize_streaming_response(
        &mut self, 
        message_id: Uuid,
        finish_reason: Option<String>,
        usage: Option<TokenUsage>,
    ) -> Result<()> {
        let msg_node = self.message_pool.get_mut(&message_id)
            .ok_or_else(|| anyhow!("Message not found: {}", message_id))?;
        
        if let Some(RichMessageType::StreamingResponse(streaming)) = &mut msg_node.message.rich_type {
            streaming.finalize(finish_reason, usage);
            
            // æ›´æ–° metadata
            if let Some(metadata) = &mut msg_node.message.metadata {
                metadata.streaming = Some(StreamingMetadata {
                    chunks_count: streaming.chunks.len(),
                    started_at: streaming.started_at,
                    completed_at: streaming.completed_at,
                    total_duration_ms: streaming.total_duration_ms,
                    average_chunk_interval_ms: streaming.chunks.iter()
                        .filter_map(|c| c.interval_ms)
                        .map(|ms| ms as f64)
                        .sum::<f64>()
                        .checked_div((streaming.chunks.len() - 1) as f64),
                });
            }
        }
        
        // çŠ¶æ€è½¬æ¢
        self.current_state = ContextState::ProcessingLLMResponse;
        self.mark_dirty();
        
        Ok(())
    }
}
```

**æµ‹è¯•**:
- `test_begin_streaming_creates_message`
- `test_append_chunk_updates_state`
- `test_finalize_updates_metadata`
- `test_streaming_integration_flow`

---

#### Task 1.5.4: å®ç° REST API ç«¯ç‚¹ â³

**ç›®æ ‡**: å®ç° Signal-Pull æ¨¡å‹çš„ REST API

**æ–‡ä»¶**: `crates/web_service/src/routes/context_routes.rs`, `message_routes.rs`

**æ–°å¢ç«¯ç‚¹**:

##### 1. GET /contexts/{id}

```rust
#[derive(Serialize)]
struct ContextMetadataResponse {
    context_id: Uuid,
    current_state: ContextState,
    active_branch: String,
    branches: HashMap<String, BranchInfo>,
    config: ContextConfig,
}

#[get("/contexts/{context_id}")]
async fn get_context_metadata(
    context_id: Path<Uuid>,
    context_manager: Data<Arc<ContextManager>>,
) -> Result<Json<ContextMetadataResponse>> {
    let context = context_manager.load_context(*context_id).await?;
    
    Ok(Json(ContextMetadataResponse {
        context_id: context.id,
        current_state: context.current_state,
        active_branch: context.active_branch_name,
        branches: context.branches.iter().map(|(name, branch)| {
            (name.clone(), BranchInfo {
                name: branch.name.clone(),
                message_ids: branch.message_ids.clone(),
                parent_branch: branch.parent_branch.clone(),
            })
        }).collect(),
        config: context.config,
    }))
}
```

##### 2. GET /contexts/{id}/messages?ids={...}

```rust
#[derive(Deserialize)]
struct BatchMessageQuery {
    ids: String,  // é€—å·åˆ†éš”çš„ UUID
}

#[get("/contexts/{context_id}/messages")]
async fn get_messages_batch(
    context_id: Path<Uuid>,
    query: Query<BatchMessageQuery>,
    storage: Data<Arc<MessageStorage>>,
) -> Result<Json<Vec<InternalMessage>>> {
    let message_ids: Vec<Uuid> = query.ids
        .split(',')
        .filter_map(|id| Uuid::parse_str(id.trim()).ok())
        .collect();
    
    let messages = storage.get_messages_batch(*context_id, &message_ids).await?;
    
    Ok(Json(messages))
}
```

##### 3. GET /contexts/{id}/messages/{msg_id}/content

```rust
#[derive(Deserialize)]
struct ContentQuery {
    from_sequence: Option<u64>,
}

#[derive(Serialize)]
struct ContentChunk {
    sequence: u64,
    delta: String,
}

#[get("/contexts/{context_id}/messages/{message_id}/content")]
async fn get_message_content_incremental(
    path: Path<(Uuid, Uuid)>,
    query: Query<ContentQuery>,
    storage: Data<Arc<MessageStorage>>,
) -> Result<Json<Vec<ContentChunk>>> {
    let (context_id, message_id) = path.into_inner();
    let from_sequence = query.from_sequence.unwrap_or(0);
    
    let message = storage.get_message(context_id, message_id).await?;
    
    // å¦‚æœæ˜¯ StreamingResponseï¼Œè¿”å›å¢é‡å—
    if let Some(RichMessageType::StreamingResponse(streaming)) = message.rich_type {
        let chunks: Vec<ContentChunk> = streaming.chunks
            .into_iter()
            .filter(|chunk| chunk.sequence > from_sequence)
            .map(|chunk| ContentChunk {
                sequence: chunk.sequence,
                delta: chunk.delta,
            })
            .collect();
        
        Ok(Json(chunks))
    } else {
        // éæµå¼æ¶ˆæ¯ï¼Œè¿”å›å®Œæ•´å†…å®¹
        let content = message.content.iter()
            .filter_map(|part| part.text_content())
            .collect::<Vec<_>>()
            .join("\n");
        
        Ok(Json(vec![ContentChunk {
            sequence: 1,
            delta: content,
        }]))
    }
}
```

**æµ‹è¯•**:
- `test_get_context_metadata`
- `test_batch_get_messages`
- `test_incremental_content_pull`
- `test_content_pull_with_sequence`

---

#### Task 1.5.5: å®ç° SSE ä¿¡ä»¤æ¨é€ â³

**ç›®æ ‡**: å®ç°è½»é‡çº§çš„ SSE ä¿¡ä»¤é€šé“

**æ–‡ä»¶**: `crates/web_service/src/routes/sse_routes.rs`

**å®ç°**:

```rust
use actix_web::{get, web::{Data, Path}, HttpResponse};
use actix_web_lab::sse::{self, Sse};
use futures_util::stream;
use tokio::sync::broadcast;

#[derive(Clone, Serialize, Deserialize)]
#[serde(tag = "event", rename_all = "snake_case")]
pub enum SSESignal {
    StateChanged {
        state: ContextState,
    },
    MessageCreated {
        message_id: Uuid,
        role: String,
    },
    ContentDelta {
        message_id: Uuid,
        sequence: u64,
    },
    MessageCompleted {
        message_id: Uuid,
        final_sequence: u64,
    },
    Error {
        error_message: String,
    },
}

#[get("/contexts/{context_id}/stream")]
async fn context_sse_stream(
    context_id: Path<Uuid>,
    broadcast_tx: Data<broadcast::Sender<(Uuid, SSESignal)>>,
) -> Sse<impl futures_util::Stream<Item = Result<sse::Event, std::io::Error>>> {
    let context_id = *context_id;
    let mut rx = broadcast_tx.subscribe();
    
    let stream = stream::unfold(rx, move |mut rx| async move {
        loop {
            match rx.recv().await {
                Ok((ctx_id, signal)) if ctx_id == context_id => {
                    // åªæ¨é€å±äºè¿™ä¸ª Context çš„ä¿¡ä»¤
                    let json = serde_json::to_string(&signal).ok()?;
                    let event = sse::Event::Data(sse::Data::new(json));
                    return Some((Ok(event), rx));
                }
                Ok(_) => continue,  // å¿½ç•¥å…¶ä»– Context çš„ä¿¡ä»¤
                Err(broadcast::error::RecvError::Lagged(_)) => {
                    // å®¢æˆ·ç«¯å¤ªæ…¢ï¼Œè·³è¿‡ä¸€äº›ä¿¡ä»¤ï¼ˆæ²¡å…³ç³»ï¼Œä¼šè‡ªåŠ¨ä¿®å¤ï¼‰
                    continue;
                }
                Err(_) => return None,
            }
        }
    });
    
    Sse::from_stream(stream)
}

// åœ¨ Context ä¸­å‘é€ä¿¡ä»¤
impl ChatContext {
    pub fn send_signal(&self, signal: SSESignal, broadcast_tx: &broadcast::Sender<(Uuid, SSESignal)>) {
        let _ = broadcast_tx.send((self.id, signal));
    }
}
```

**æµ‹è¯•**:
- `test_sse_connection`
- `test_signal_filtering`
- `test_lagged_client_handling`

---

#### Task 1.5.6: å­˜å‚¨å±‚å®ç° â³

**ç›®æ ‡**: å®ç° Context-Local Message Pool å­˜å‚¨

**æ–‡ä»¶**: `crates/context_manager/src/storage/message_storage.rs`

**å®ç°**:

```rust
use std::path::{Path, PathBuf};
use tokio::fs;
use uuid::Uuid;

pub struct FileSystemMessageStorage {
    base_path: PathBuf,
}

impl FileSystemMessageStorage {
    pub fn new(base_path: PathBuf) -> Self {
        Self { base_path }
    }
    
    fn context_dir(&self, context_id: Uuid) -> PathBuf {
        self.base_path.join("contexts").join(context_id.to_string())
    }
    
    fn messages_pool_dir(&self, context_id: Uuid) -> PathBuf {
        self.context_dir(context_id).join("messages_pool")
    }
    
    fn message_path(&self, context_id: Uuid, message_id: Uuid) -> PathBuf {
        self.messages_pool_dir(context_id).join(format!("{}.json", message_id))
    }
    
    fn metadata_path(&self, context_id: Uuid) -> PathBuf {
        self.context_dir(context_id).join("metadata.json")
    }
    
    // ä¿å­˜æ¶ˆæ¯
    pub async fn save_message(
        &self, 
        context_id: Uuid, 
        message_id: Uuid, 
        message: &InternalMessage
    ) -> Result<()> {
        let path = self.message_path(context_id, message_id);
        fs::create_dir_all(path.parent().unwrap()).await?;
        
        let json = serde_json::to_string_pretty(message)?;
        fs::write(path, json).await?;
        
        Ok(())
    }
    
    // è·å–æ¶ˆæ¯
    pub async fn get_message(
        &self, 
        context_id: Uuid, 
        message_id: Uuid
    ) -> Result<InternalMessage> {
        let path = self.message_path(context_id, message_id);
        let json = fs::read_to_string(path).await?;
        let message = serde_json::from_str(&json)?;
        Ok(message)
    }
    
    // æ‰¹é‡è·å–
    pub async fn get_messages_batch(
        &self, 
        context_id: Uuid, 
        message_ids: &[Uuid]
    ) -> Result<Vec<InternalMessage>> {
        let mut messages = Vec::new();
        for id in message_ids {
            if let Ok(msg) = self.get_message(context_id, *id).await {
                messages.push(msg);
            }
        }
        Ok(messages)
    }
    
    // ä¿å­˜ metadata
    pub async fn save_metadata(
        &self, 
        context_id: Uuid, 
        metadata: &ContextMetadata
    ) -> Result<()> {
        let path = self.metadata_path(context_id);
        fs::create_dir_all(path.parent().unwrap()).await?;
        
        let json = serde_json::to_string_pretty(metadata)?;
        fs::write(path, json).await?;
        
        Ok(())
    }
    
    // åˆ é™¤ Contextï¼ˆä¸€æ­¥å®Œæˆï¼Œæ— éœ€ GCï¼‰
    pub async fn delete_context(&self, context_id: Uuid) -> Result<()> {
        let dir = self.context_dir(context_id);
        if dir.exists() {
            fs::remove_dir_all(dir).await?;
        }
        Ok(())
    }
}
```

**æµ‹è¯•**:
- `test_save_and_get_message`
- `test_batch_get_messages`
- `test_delete_context_removes_all`
- `test_concurrent_write`

---

#### Task 1.5.7: åˆ›å»º spec delta â³

**æ–‡ä»¶**: `openspec/changes/refactor-context-session-architecture/specs/sync/spec.md`

```markdown
## ADDED Requirements

### Requirement: Signal-Pull Synchronization

The system SHALL implement a signal-pull synchronization model for frontend-backend state updates.

#### Scenario: Frontend receives content delta signal

- **GIVEN** a message is being streamed
- **WHEN** a new chunk arrives at the backend
- **THEN** the backend SHALL send a `ContentDelta` SSE event with message_id and sequence number
- **AND** the event SHALL NOT contain the text content

#### Scenario: Frontend pulls incremental content

- **GIVEN** the frontend receives a `ContentDelta` signal with sequence N
- **AND** the local sequence is M < N
- **WHEN** the frontend calls GET /messages/{id}/content?from_sequence=M
- **THEN** the backend SHALL return all chunks with sequence > M
- **AND** the chunks SHALL be in ascending sequence order

#### Scenario: Auto-healing from missed signals

- **GIVEN** the frontend missed signals for sequence 2 and 3
- **AND** the local sequence is 1
- **WHEN** the frontend receives signal for sequence 4
- **THEN** the frontend SHALL pull content from sequence 1
- **AND** the backend SHALL return chunks [2, 3, 4]
- **AND** the frontend state SHALL be fully synchronized

### Requirement: Context-Local Message Pool

The system SHALL store all messages for a context within the context's own directory.

#### Scenario: Context deletion

- **GIVEN** a context with 100 messages across 3 branches
- **WHEN** the context is deleted
- **THEN** the system SHALL remove the entire context directory
- **AND** no garbage collection SHALL be required
- **AND** no orphaned message files SHALL remain

#### Scenario: Branch creation

- **GIVEN** a context with a main branch containing messages [A, B, C]
- **WHEN** a new branch is created from main
- **THEN** the new branch SHALL reference the same message IDs
- **AND** no message files SHALL be copied or duplicated
- **AND** the operation SHALL complete in < 10ms
```

---

#### Task 1.5.8: æ›´æ–° tasks.md â³

åœ¨ Phase 1 å’Œ Phase 2 ä¹‹é—´æ’å…¥ Phase 1.5ã€‚

---

## ğŸ“Š å·¥ä½œé‡ä¼°ç®—

| ä»»åŠ¡ | æ–‡ä»¶æ•° | é¢„è®¡ä»£ç è¡Œæ•° | æµ‹è¯•ç”¨ä¾‹ | é¢„è®¡æ—¶é—´ |
|------|--------|-------------|---------|---------|
| MessageMetadata æ‰©å±• | 1 | ~150 | 5 | 2 å°æ—¶ |
| StreamingResponse ç±»å‹ | 1 | ~200 | 6 | 3 å°æ—¶ |
| Context é›†æˆ | 1 | ~150 | 4 | 2 å°æ—¶ |
| REST API ç«¯ç‚¹ | 2 | ~300 | 8 | 4 å°æ—¶ |
| SSE ä¿¡ä»¤æ¨é€ | 1 | ~150 | 3 | 3 å°æ—¶ |
| å­˜å‚¨å±‚å®ç° | 1 | ~250 | 5 | 3 å°æ—¶ |
| Spec delta å’Œæ–‡æ¡£ | 2 | ~200 (markdown) | - | 2 å°æ—¶ |
| é›†æˆæµ‹è¯• | 1 | ~200 | 3 | 2 å°æ—¶ |
| **æ€»è®¡** | **10** | **~1,600** | **34** | **~21 å°æ—¶** |

**é¢„è®¡å®Œæˆæ—¶é—´**: 2-3 å¤©ï¼ˆåŒ…å«æµ‹è¯•å’Œæ–‡æ¡£ï¼‰

---

## âš ï¸ é£é™©å’Œç¼“è§£æªæ–½

### é£é™© 1: SSE è¿æ¥ç¨³å®šæ€§

**é—®é¢˜**: SSE é•¿è¿æ¥å¯èƒ½è¢«ä»£ç†ã€é˜²ç«å¢™ä¸­æ–­

**ç¼“è§£**:
- å®ç°å¿ƒè·³æœºåˆ¶ï¼ˆæ¯ 30 ç§’å‘é€ pingï¼‰
- å‰ç«¯è‡ªåŠ¨é‡è¿ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
- çŠ¶æ€è‡ªåŠ¨æ¢å¤ï¼ˆé€šè¿‡åºåˆ—å·ï¼‰

### é£é™© 2: å­˜å‚¨å±‚æ€§èƒ½

**é—®é¢˜**: å¤§é‡å°æ–‡ä»¶å¯èƒ½å½±å“æ€§èƒ½

**ç¼“è§£**:
- ç°ä»£æ–‡ä»¶ç³»ç»Ÿï¼ˆext4, APFSï¼‰å¤„ç†å°æ–‡ä»¶å¾ˆé«˜æ•ˆ
- æ¶ˆæ¯æŒ‰ Context éš”ç¦»ï¼Œé¿å…å•ç›®å½•æ–‡ä»¶è¿‡å¤š
- æœªæ¥å¯ä¼˜åŒ–ä¸ºæ‰¹é‡å†™å…¥æˆ– SQLiteï¼ˆä¿æŒæ¥å£ä¸å˜ï¼‰

### é£é™© 3: åºåˆ—å·ä¸ä¸€è‡´

**é—®é¢˜**: å¹¶å‘æƒ…å†µä¸‹åºåˆ—å·å¯èƒ½é”™ä¹±

**ç¼“è§£**:
- ä½¿ç”¨åŸå­æ“ä½œï¼ˆAtomicU64ï¼‰ç®¡ç†åºåˆ—å·
- åœ¨ StreamingResponse å†…éƒ¨ç»´æŠ¤åºåˆ—
- å•çº¿ç¨‹æµå¼å†™å…¥ï¼ˆé¿å…ç«æ€ï¼‰

---

## ğŸ¯ éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] Context å¯ä»¥ç‹¬ç«‹å¤‡ä»½/æ¢å¤ï¼ˆå•æ–‡ä»¶å¤¹æ“ä½œï¼‰
- [ ] åˆ†æ”¯åˆ›å»º/åˆå¹¶ä¸æ¶‰åŠæ–‡ä»¶ I/O
- [ ] SSE ä¿¡ä»¤ payload < 1KB
- [ ] å‰ç«¯å¯ä»¥ä»ä»»æ„åºåˆ—å·æ‹‰å–å†…å®¹
- [ ] ä¿¡ä»¤ä¸¢å¤±æ—¶å‰ç«¯è‡ªåŠ¨ä¿®å¤çŠ¶æ€

### æ€§èƒ½éªŒæ”¶
- [ ] åˆ†æ”¯åˆ›å»º < 10ms
- [ ] åˆ é™¤ Context < 100msï¼ˆ100 æ¡æ¶ˆæ¯ï¼‰
- [ ] SSE ä¿¡ä»¤å»¶è¿Ÿ < 50ms
- [ ] å¢é‡å†…å®¹æ‹‰å– < 100ms

### æµ‹è¯•éªŒæ”¶
- [ ] å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 90%
- [ ] é›†æˆæµ‹è¯•è¦†ç›–ä¸»è¦åœºæ™¯
- [ ] è´Ÿè½½æµ‹è¯•ï¼ˆæ¨¡æ‹Ÿ 10 ä¸ªå¹¶å‘æµå¼å“åº”ï¼‰
- [ ] ç½‘ç»œå¼‚å¸¸æµ‹è¯•ï¼ˆæ¨¡æ‹Ÿä¿¡ä»¤ä¸¢å¤±ï¼‰

---

## ğŸ“ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

1. **ç«‹å³å¼€å§‹**: Task 1.5.1 - æ‰©å±• MessageMetadata
2. **å¹¶è¡Œå¼€å‘**: å¯ä»¥åŒæ—¶è¿›è¡Œ StreamingResponse å’Œ Storage å±‚å¼€å‘
3. **é›†æˆæµ‹è¯•**: å®Œæˆæ ¸å¿ƒåŠŸèƒ½åç«‹å³è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•
4. **æ–‡æ¡£å®Œå–„**: è¾¹å¼€å‘è¾¹æ›´æ–° API æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹

---

**çŠ¶æ€**: å‡†å¤‡å°±ç»ªï¼Œç­‰å¾…å®æ–½æŒ‡ä»¤ ğŸš€

